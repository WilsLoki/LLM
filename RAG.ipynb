{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilsLoki/LLM/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VmGjvxrspN1"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install sentence_transformers\n",
        "!pip install transformers\n",
        "!pip install openai\n",
        "!pip install unstructured\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu\n",
        "!pip install pypdf\n",
        "!pip install -U langchain-community\n",
        "!pip install -U langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox8Of0vFtC_Z"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import getpass\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vWxYFmrtKw3"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxtkYkKntOFA",
        "outputId": "8ea1b8f0-984c-44a7-f61f-13639227c9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 52 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 54 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 56 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 58 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 60 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 62 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 74 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 81 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 89 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 108 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 110 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 167 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 181 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 258 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 305 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 307 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 411 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 457 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 526 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 597 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 627 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 720 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文档数量: 71\n",
            "第32个文档示例: page_content='4\n",
            "©2024.12 iResearchInc.                                                                                                                         www.iresearch.com.cn\n",
            "AI大模型是什么？AI大模型作为人工智能领域的重要突破，其超大规模参数和超强计算资源使得机器能够处理海量数据，完成各种复杂任务AI大模型，通常指的是基于深度学习技术构建的、具有大量参数和强大功能的的人工智能模型。数据、算力和算法是AI大模型发展的三大核心要素。这些模型通过学习海量数据和深度神经网络的优化，在各种任务上取得了显著成果。\n",
            "来源：专家访谈，公开资料，艾瑞消费研究院自主研究及绘制。\n",
            "算法算力\n",
            "数据\n",
            "AI大模型是什么？通常指的是基于深度学习技术构建的、具有大量参数和强大功能的的人工智能模型。这些模型能够处理和理解大规模的数据，并在多种复杂的任务中表现出色。它们的作用类似于大脑，可以处理和分析大量数据。这些模型通过训练过程学习，以执行各种任务，让计算机获得类似人类的“思考”能力。核心三要素数据：AI大模型需要大规模的训练数据来支持其复杂的网络结构和参数学习。数据的数量越多，模型能够学习到的信息就越全面，在处理各种任务时表现出更高的泛化能力。算力：AI大模型的训练需要高性能的计算硬件支持，如GPU、TPU等，大算力能够加速模型的训练过程，使得复杂模型的训练在合理的时间内完成。算法：算法指的是一系列解决问题的步骤和规则，这些步骤和规则是模型处理数据、学习知识和完成任务的基础。' metadata={'producer': 'macOS 版本11.3（版号20E232） Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20241213025705Z00'00'\", 'moddate': \"D:20241213025705Z00'00'\", 'source': 'intelligent _cockpit.pdf', 'total_pages': 42, 'page': 3, 'page_label': '4'}\n"
          ]
        }
      ],
      "source": [
        "# 创建知识库文档\n",
        "\n",
        "# 下载文档\n",
        "def download_file(url, filename):\n",
        "    response = requests.get(url)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "download_file('https://wx.mail.qq.com/ftn/download?func=4&key=9ccd4666efb9e0a0aebe1966356163312ecb5e6637616331461d4f125457015054571a540e51541c015455561a035154521f045e005800035003075103507b310a5c43035b0d0a56065c434668020c5208425e121911075777cd605468779f379f5ad9323b22592b0d9288edaf6163316332376637&code=c27f7ac1', 'intelligent _cockpit.pdf')\n",
        "download_file('https://wx.mail.qq.com/ftn/download?func=4&key=9a9c5238e1bbb5a9a8ef1b383b6336386f8d1f3839633638404c4d4c5f020f5a565b18010f555715565654011400000c534e535c5c560e0e010150085f02383804116a5f5502454b00101b485d0522187d5b418fa55b34ffda070c845a9b11a1ad78f83839633638656335&code=ec589c68', 'ar_glasses.pdf')\n",
        "\n",
        "# 加载文档\n",
        "loaders = [\n",
        "    PyPDFLoader('ar_glasses.pdf'),\n",
        "    PyPDFLoader('intelligent _cockpit.pdf')\n",
        "]\n",
        "\n",
        "# 存储文档\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())\n",
        "\n",
        "# 验证：文档部分正常\n",
        "print(f\"文档数量: {len(docs)}\")\n",
        "print(f\"第32个文档示例: {docs[32]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEvbCA8ZtvWU",
        "outputId": "c1cf7572-21b2-426e-87a5-e5744893ba9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 329, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 312, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 304, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 305, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 332, which is longer than the specified 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分割后的文档数量: 213\n",
            "第101个分割示例: page_content='来源：公开资料，艾瑞消费研究院自主研究及绘制。\n",
            "阿里云推出的通用大模型，具备广泛的任务处理能力，包括文本生成、问答、翻译等。创意文案：根据产品介绍自动撰写营销文案，修改润色文章，生成直播带货剧本等办公助理：提供SWOT分析、PPT框架生成等学习助手：应用于学科试题生成、制定个性化学习路径规划等……\n",
            "百度开发的人工智能大语言模型，具备文本生成、语音合成、多语言支持、实时翻译、智能断句和个性化设置等能力。内容创作：撰写商业计划、市场分析报告等商业文案多模态：支持图像生成、图像处理、语音识别、音频分类等逻辑推理：进行数学计算、常识推理、逻辑校验、代码纠错等……' metadata={'producer': 'macOS 版本11.3（版号20E232） Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20241213025705Z00'00'\", 'moddate': \"D:20241213025705Z00'00'\", 'source': 'intelligent _cockpit.pdf', 'total_pages': 42, 'page': 8, 'page_label': '9'}\n"
          ]
        }
      ],
      "source": [
        "# 文本分割\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30, separator='\\n')\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# 验证：文本分割正常\n",
        "print(f\"分割后的文档数量: {len(splits)}\")\n",
        "print(f\"第101个分割示例: {splits[101]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTadS55-t0TZ"
      },
      "outputs": [],
      "source": [
        "# 文本嵌入\n",
        "embeddings = HuggingFaceEmbeddings(model_name='moka-ai/m3e-base')\n",
        "\n",
        "# 存储向量\n",
        "vector_store = FAISS.from_documents(splits, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZ1SSBWt6uM"
      },
      "source": [
        "## LLM (ERNIE-Speed-128K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UPukBULuFXC"
      },
      "outputs": [],
      "source": [
        "# 定义类\n",
        "class BaiduErnie:\n",
        "    host = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-speed-128k\"  # ERNIE-Speed-128K 模型请求地址\n",
        "\n",
        "    def __init__(self):\n",
        "        # 在运行时获取 client_id 和 client_secret\n",
        "        self.client_id = getpass.getpass(\"输入 client_id: \")\n",
        "        self.client_secret = getpass.getpass(\"输入 client_secret: \")\n",
        "        self.get_access_token()\n",
        "\n",
        "    # 定义获取 access token 方法(method)\n",
        "    def get_access_token(self):\n",
        "        url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={self.client_id}&client_secret={self.client_secret}\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            self.access_token = response.json()[\"access_token\"]\n",
        "            return self.access_token\n",
        "        else:\n",
        "            raise Exception(\"获取 access_token 失败\")\n",
        "\n",
        "    # 定义 chat 方法(method)\n",
        "    def chat(self, prompt: str, user_id: str = \"default_user\"):\n",
        "        # 单轮对话方法（无上下文）\n",
        "        url = f\"{self.host}?access_token={self.access_token}\"\n",
        "        # 构建请求参数\n",
        "        data = {\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"user_id\": user_id\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # 发送请求\n",
        "            response = requests.post(url, json=data)\n",
        "            # 检查响应状态码\n",
        "            response.raise_for_status()\n",
        "            # 响应处理\n",
        "            result = response.json()\n",
        "            return result.get(\"result\", \"\")\n",
        "        # 异常处理\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise Exception(f\"对话请求失败: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6bSCB85uOnp",
        "outputId": "68c28db3-316d-4ce1-a102-6d3c30fe1feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "输入 client_id: ··········\n",
            "输入 client_secret: ··········\n",
            "您好，我是由百度公司开发的人工智能语言模型，我的中文名是文心一言，英文名是ERNIE Bot。如果您有任何问题或需要帮助，可以随时向我提问。希望我的回答能够真正为您带来帮助。\n"
          ]
        }
      ],
      "source": [
        "# 创建实例对象\n",
        "baidu_ernie = BaiduErnie()\n",
        "\n",
        "# 验证：大模型调用正常\n",
        "response = baidu_ernie.chat(prompt='你是哪家公司开发的什么大语言模型？')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7HQm0PKuUHp"
      },
      "outputs": [],
      "source": [
        "# 定义 chat 函数（封装）\n",
        "def chat(prompt):\n",
        "    result = baidu_ernie.chat(prompt=prompt)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZYOTP4AuVG8"
      },
      "source": [
        "## Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义question和检索数量\n",
        "question = '千悟大模型对鸿蒙座舱的提升有哪些'\n",
        "K = 5"
      ],
      "metadata": {
        "id": "shPalfOqK7nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 检索 + 重排\n",
        "docs_and_scores = vector_store.similarity_search_with_score(question, k=K)\n",
        "\n",
        "# 打印检索结果\n",
        "for doc, score in docs_and_scores:\n",
        "    source = doc.metadata['source']\n",
        "    content = doc.page_content\n",
        "    print(f'来源 {source} 字数 {len(content)} 匹配度 {score:.2f}')\n",
        "    print(content[:100] + '……')\n",
        "    print('------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJRPiuCSIW3p",
        "outputId": "d7b3ec94-8069-4782-96cd-0361d03d4aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "来源 intelligent _cockpit.pdf 字数 256 匹配度 128.05\n",
            "对座舱的提升提升智能语音交互体验：千悟大模型的加持下，智能座舱中的语音助手（小艺）对用户指令的理解和执行更加智能和高效。提升舱内人体姿态感知：千悟大模型提高座舱的高精度感知能力和多模态融合控车技术。实……\n",
            "------------------\n",
            "来源 intelligent _cockpit.pdf 字数 258 匹配度 130.92\n",
            "32\n",
            "©2024.12 iResearchInc.                                                                           ……\n",
            "------------------\n",
            "来源 intelligent _cockpit.pdf 字数 317 匹配度 141.94\n",
            "l增强识别和纠错能力：语音助手能够更准确地理解用户的指令，识别用户声纹甚至复刻声纹，能够进行自动纠错语音指令，并提供正确的内容。l提升自适应聆听能力：语音助手能够听懂用户在表达过程中的犹豫停顿，自动地……\n",
            "------------------\n",
            "来源 intelligent _cockpit.pdf 字数 109 匹配度 144.55\n",
            "来源：公开资料，艾瑞消费研究院自主研究及绘制。\n",
            "千悟大模型华为智能汽车解决方案为鸿蒙座舱打造的专属于用车场景的融合感知决策大模型，深度集成了视觉感知、语音交互、车控传感器等多种技术，实现了多模态信息的……\n",
            "------------------\n",
            "来源 intelligent _cockpit.pdf 字数 67 匹配度 164.35\n",
            "大模型技术已赋予座舱更加准确、流畅、自然的语音交互体验，未来随着AI Agent的应用，汽车智能座舱将获得更加情感化和拟人化的交互体验……\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "rJsm4d7vCXqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT62c3sHuY8M"
      },
      "outputs": [],
      "source": [
        "# 定义 predict 函数\n",
        "def predict(question, docs_and_scores):\n",
        "\n",
        "    # 生成上下文\n",
        "    context = ''\n",
        "    for doc in docs_and_scores:\n",
        "        context += doc[0].page_content\n",
        "        context += '\\n'\n",
        "\n",
        "    # 提示词增强\n",
        "    prompt = f'你是一个专注于知识理解和解答的 AI 助手，请基于以下已知信息回答问题。你只需要回答和已知信息相关的问题，如果问题和已知信息不相关，你可以直接回答\"不知道\" 问题：{question} 已知信息:{context}'\n",
        "\n",
        "    # 调用大模型获取结果\n",
        "    result = chat(prompt)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAOs-xDHuccd",
        "outputId": "ffb71499-41c5-4832-f2ec-0f8f181d414a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "基于已知信息，千悟大模型对鸿蒙座舱的提升主要体现在以下几个方面：\n",
            "\n",
            "1. 提升智能语音交互体验：通过千悟大模型的加持，智能座舱中的语音助手对用户指令的理解和执行更加智能和高效。\n",
            "2. 提升舱内人体姿态感知：千悟大模型提高座舱的高精度感知能力和多模态融合控车技术，实现跨设备互联与无缝流转。\n",
            "3. 实现个性化与智能化服务：千悟大模型通过深度学习和用户行为分析，能够为用户提供更加个性化的服务和建议。\n",
            "4. 增强识别和纠错能力：语音助手能够更准确地理解用户的指令，识别用户声纹并进行自动纠错语音指令。\n",
            "5. 提升自适应聆听能力：语音助手能够听懂用户在表达过程中的犹豫停顿，自动地延长聆听等待时间。\n",
            "6. 融合感知决策：千悟大模型深度集成了视觉感知、语音交互、车控传感器等多种技术，实现了多模态信息的融合感知和综合决策。\n",
            "\n",
            "由此可见，千悟大模型在提升鸿蒙座舱的智能交互体验、感知能力、个性化服务以及多模态融合决策等方面发挥了重要作用。\n"
          ]
        }
      ],
      "source": [
        "predict(question, docs_and_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC1YIM2kiBCl9YzNXvM06H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}